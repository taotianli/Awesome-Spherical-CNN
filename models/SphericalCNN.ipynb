{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "\n",
    "class onering_conv_layer(nn.Module):\n",
    "    \"\"\"The convolutional layer on icosahedron discretized sphere using \n",
    "    1-ring filter\n",
    "    \n",
    "    Parameters:\n",
    "            in_feats (int) - - input features/channels\n",
    "            out_feats (int) - - output features/channels\n",
    "            \n",
    "    Input: \n",
    "        N x in_feats tensor\n",
    "    Return:\n",
    "        N x out_feats tensor\n",
    "    \"\"\"  \n",
    "    def __init__(self, in_feats, out_feats, neigh_orders, neigh_indices=None, neigh_weights=None):\n",
    "        super(onering_conv_layer, self).__init__()\n",
    "\n",
    "        self.in_feats = in_feats\n",
    "        self.out_feats = out_feats\n",
    "        self.neigh_orders = neigh_orders\n",
    "        self.pool = pool_layer(self.neigh_orders, pooling_type='mean')\n",
    "        self.weight = nn.Linear(7 * in_feats, out_feats)\n",
    "        # self.norm = nn.BatchNorm1d(out_feats, momentum=0.15, affine=True, track_running_stats=False)\n",
    "        # self.relu = nn.LeakyReLU(0.2, inplace=True)\n",
    "        # self.dropout = nn.Dropout(0.7)\n",
    "        \n",
    "    def forward(self, x):\n",
    "       \n",
    "        mat = x[self.neigh_orders].view(len(x), 7*self.in_feats)\n",
    "                \n",
    "        out_features = self.weight(mat)\n",
    "        # out_features = self.norm(out_features)\n",
    "        # out_features = self.relu(out_features)\n",
    "        # out_features = self.pool(out_features)\n",
    "        # out_features = self.dropout(out_features)\n",
    "        \n",
    "        return out_features\n",
    "    \n",
    "class tworing_conv_layer(nn.Module):\n",
    "    \"\"\"The convolutional layer on icosahedron discretized sphere using \n",
    "    2-ring filter\n",
    "    \n",
    "    Parameters:\n",
    "            in_feats (int) - - input features/channels\n",
    "            out_feats (int) - - output features/channels\n",
    "            \n",
    "    Input: \n",
    "        N x in_feats tensor\n",
    "    Return:\n",
    "        N x out_feats tensor\n",
    "    \"\"\"  \n",
    "    def __init__(self, in_feats, out_feats, neigh_orders):\n",
    "        super(tworing_conv_layer, self).__init__()\n",
    "\n",
    "        self.in_feats = in_feats\n",
    "        self.out_feats = out_feats\n",
    "        self.neigh_orders = neigh_orders\n",
    "        \n",
    "        self.weight = nn.Linear(19 * in_feats, out_feats)\n",
    "        \n",
    "    def forward(self, x):\n",
    "       \n",
    "        mat = x[self.neigh_orders].view(len(x), 19*self.in_feats)\n",
    "\n",
    "        out_features = self.weight(mat)\n",
    "        return out_features\n",
    "    \n",
    "\n",
    "class pool_layer(nn.Module):\n",
    "    \"\"\"\n",
    "    The pooling layer on icosahedron discretized sphere using 1-ring filter\n",
    "    \n",
    "    Input: \n",
    "        N x D tensor\n",
    "    Return:\n",
    "        ((N+6)/4) x D tensor\n",
    "    \n",
    "    \"\"\"  \n",
    "\n",
    "    def __init__(self, neigh_orders, pooling_type='mean'):\n",
    "        super(pool_layer, self).__init__()\n",
    "\n",
    "        self.neigh_orders = neigh_orders\n",
    "        self.pooling_type = pooling_type\n",
    "        \n",
    "    def forward(self, x):\n",
    "       \n",
    "        num_nodes = int((x.size()[0]+6)/4)\n",
    "        feat_num = x.size()[1]\n",
    "        x = x[self.neigh_orders[0:num_nodes*7]].view(num_nodes, feat_num, 7)\n",
    "        if self.pooling_type == \"mean\":\n",
    "            x = torch.mean(x, 2)\n",
    "        if self.pooling_type == \"max\":\n",
    "            x = torch.max(x, 2)\n",
    "            assert(x[0].size() == torch.Size([num_nodes, feat_num]))\n",
    "            return x[0], x[1]\n",
    "        \n",
    "        assert(x.size() == torch.Size([num_nodes, feat_num]))\n",
    "                \n",
    "        return x\n",
    "    \n",
    "class upconv_layer(nn.Module):\n",
    "    \"\"\"\n",
    "    The transposed convolution layer on icosahedron discretized sphere using 1-ring filter\n",
    "    \n",
    "    Input: \n",
    "        N x in_feats, tensor\n",
    "    Return:\n",
    "        ((Nx4)-6) x out_feats, tensor\n",
    "    \n",
    "    \"\"\"  \n",
    "\n",
    "    def __init__(self, in_feats, out_feats, upconv_top_index, upconv_down_index):\n",
    "        super(upconv_layer, self).__init__()\n",
    "\n",
    "        self.in_feats = in_feats\n",
    "        self.out_feats = out_feats\n",
    "        self.upconv_top_index = upconv_top_index\n",
    "        self.upconv_down_index = upconv_down_index\n",
    "        self.weight = nn.Linear(in_feats, 7 * out_feats)\n",
    "        \n",
    "    def forward(self, x):\n",
    "       \n",
    "        raw_nodes = x.size()[0]\n",
    "        new_nodes = int(raw_nodes*4 - 6)\n",
    "        x = self.weight(x)\n",
    "        x = x.view(len(x) * 7, self.out_feats)\n",
    "        x1 = x[self.upconv_top_index]\n",
    "        assert(x1.size() == torch.Size([raw_nodes, self.out_feats]))\n",
    "        x2 = x[self.upconv_down_index].view(-1, self.out_feats, 2)\n",
    "        x = torch.cat((x1,torch.mean(x2, 2)), 0)\n",
    "        assert(x.size() == torch.Size([new_nodes, self.out_feats]))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "\n",
    "def my_mat_Get_2ring_neighs_order():\n",
    "    neigh_orders_2ring_40962 = my_mat_get_2ring_neighs_order('neighbour_indices_matlab/adj_mat_order_2ring_40962.mat')\n",
    "    neigh_orders_2ring_10242 = my_mat_get_2ring_neighs_order('neighbour_indices_matlab/adj_mat_order_2ring_10242.mat')\n",
    "    neigh_orders_2ring_2562 = my_mat_get_2ring_neighs_order('neighbour_indices_matlab/adj_mat_order_2ring_2562.mat')\n",
    "    neigh_orders_2ring_642 = my_mat_get_2ring_neighs_order('neighbour_indices_matlab/adj_mat_order_2ring_642.mat')\n",
    "    neigh_orders_2ring_162 = my_mat_get_2ring_neighs_order('neighbour_indices_matlab/adj_mat_order_2ring_162.mat')\n",
    "    neigh_orders_2ring_42 = my_mat_get_2ring_neighs_order('neighbour_indices_matlab/adj_mat_order_2ring_42.mat')\n",
    "    \n",
    "    return neigh_orders_2ring_40962, neigh_orders_2ring_10242, neigh_orders_2ring_2562, neigh_orders_2ring_642, neigh_orders_2ring_162, neigh_orders_2ring_42\n",
    "\n",
    "def my_mat_get_2ring_neighs_order(order_path):\n",
    "    adj_mat_order = sio.loadmat(order_path)\n",
    "    adj_mat_order = adj_mat_order['adj_mat_order_2ring']\n",
    "    neigh_orders = np.zeros((len(adj_mat_order), 19))\n",
    "    neigh_orders[:,0:18] = adj_mat_order-1\n",
    "    neigh_orders[:,18] = np.arange(len(adj_mat_order))\n",
    "    neigh_orders = np.ravel(neigh_orders).astype(np.int64)\n",
    "    \n",
    "    return neigh_orders\n",
    "\n",
    "neigh_orders_2ring_40962, neigh_orders_2ring_10242, neigh_orders_2ring_2562, neigh_orders_2ring_642, neigh_orders_2ring_162, neigh_orders_2ring_42 = my_mat_Get_2ring_neighs_order()\n",
    "neigh_orders_1ring_40962 = my_mat_get_2ring_neighs_order('neighbour_indices_matlab/adj_mat_order_40962.mat')\n",
    "print(neigh_orders_2ring_40962.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "################################################################\n",
    "\"\"\" hyper-parameters \"\"\"\n",
    "# cuda = torch.device('cpu')\n",
    "device = torch.device(\"cuda:0\")\n",
    "batch_size = 1\n",
    "model_name = 'Unet_infant'  # 'Unet_infant', 'Unet_18', 'Unet_2ring', 'Unet_repa', 'fcn', 'SegNet', 'SegNet_max'\n",
    "up_layer = 'upsample_interpolation' # 'upsample_interpolation', 'upsample_fixindex' \n",
    "in_channels = 1\n",
    "out_channels = 1\n",
    "learning_rate = 0.001\n",
    "momentum = 0.99\n",
    "weight_decay = 0.0001\n",
    "fold = 1 # 1,2,3 \n",
    "################################################################\n",
    "\n",
    "data_file = 'data.npy'\n",
    "label_file = 'labels.npy'\n",
    "\n",
    "# 从.npy文件中加载数据\n",
    "data_array = np.load(data_file)\n",
    "train_data = data_array[0:400,:]\n",
    "val_data = data_array[400:,:]\n",
    "print(data_array.shape,train_data.shape)\n",
    "label_array = np.load(label_file)\n",
    "train_label = label_array[0:400]\n",
    "val_label = label_array[400:]\n",
    "\n",
    "neighbors_path = 'C:/Users/DELL/Desktop/kaiti/Spherical_U-Net/neigh_indices/adj_mat_order_10242.mat'\n",
    "\n",
    "def get_neighs_order(neighbors_path):\n",
    "    adj_mat_order = sio.loadmat(neighbors_path)\n",
    "    adj_mat_order = adj_mat_order['adj_mat_order']\n",
    "    neigh_orders = np.zeros((len(adj_mat_order), 7))\n",
    "    neigh_orders[:,0:6] = adj_mat_order-1\n",
    "    neigh_orders[:,6] = np.arange(len(adj_mat_order))\n",
    "    neigh_orders = np.ravel(neigh_orders).astype(np.int64)\n",
    "    \n",
    "    return neigh_orders\n",
    "\n",
    "class BrainSphere(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, data, label):\n",
    "        self.data = data\n",
    "        self.labels = label\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = {\n",
    "            'data': torch.from_numpy(self.data[idx]),\n",
    "            'label': torch.tensor(self.labels[idx])\n",
    "        }\n",
    "        return sample\n",
    "\n",
    "\n",
    "class Spherical_CNN(nn.Module):\n",
    "    \"\"\"Define the Spherical UNet structure\n",
    "\n",
    "    \"\"\"    \n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        \"\"\" Initialize the Spherical UNet.\n",
    "\n",
    "        Parameters:\n",
    "            in_ch (int) - - input features/channels\n",
    "            out_ch (int) - - output features/channels\n",
    "        \"\"\"\n",
    "        super(Spherical_CNN, self).__init__()\n",
    "\n",
    "        #neigh_indices_10242, neigh_indices_2562, neigh_indices_642, neigh_indices_162, neigh_indices_42 = Get_indices_order()\n",
    "        #neigh_orders_10242, neigh_orders_2562, neigh_orders_642, neigh_orders_162, neigh_orders_42, neigh_orders_12 = Get_neighs_order()\n",
    "        \n",
    "        neigh_orders = get_neighs_order(neighbors_path)\n",
    "\n",
    "        \n",
    "        conv_layer = onering_conv_layer\n",
    "\n",
    "        self.block = nn.Sequential(\n",
    "            conv_layer(in_ch, 64, neigh_orders),\n",
    "            nn.BatchNorm1d(64, momentum=0.15, affine=True, track_running_stats=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.7),\n",
    "            conv_layer(64, 128, neigh_orders),\n",
    "            nn.BatchNorm1d(128, momentum=0.15, affine=True, track_running_stats=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "        self.linear = nn.Linear(10242, 1)\n",
    "            \n",
    "\n",
    "                \n",
    "        \n",
    "    def forward(self, x):\n",
    "        # batch norm version\n",
    "        x = self.block(x)\n",
    "        x = x.squeeze()\n",
    "        # print(x.shape) \n",
    "        x = self.linear(x)\n",
    "        # x = self.outc(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "# train_dataset = BrainSphere(data_file, label_file)\n",
    "train_dataset = BrainSphere(train_data, train_label)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=1, shuffle=False, pin_memory=True)\n",
    "\n",
    "val_dataset = BrainSphere(val_data, val_label)\n",
    "\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=1, shuffle=False, pin_memory=True)\n",
    "# for batch in train_dataloader:\n",
    "#     data, labels = batch['data'], batch['label']\n",
    "#     # 在这里可以进行你的训练或其他操作\n",
    "#     print(f\"Batch Data Shape: {data.shape}, Batch Label Shape: {labels.shape}\")\n",
    "\n",
    "model = Spherical_CNN(in_ch=1, out_ch=out_channels)\n",
    "\n",
    "print(\"{} paramerters in total\".format(sum(x.numel() for x in model.parameters())))\n",
    "model.to(device)\n",
    "criterion = nn.MSELoss()\n",
    "val_criterion = nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler1 = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.5)\n",
    "\n",
    "\n",
    "def train_step(data, target):\n",
    "    # model.train()\n",
    "    data, target = data.to(device), target.to(device)\n",
    "\n",
    "    prediction = model(data)\n",
    "    # print(prediction)\n",
    "    loss = criterion(prediction, target)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item(),prediction\n",
    "\n",
    "\n",
    "# # train_dice = [0, 0, 0, 0, 0]\n",
    "print('length of dataloader:', len(train_dataloader))\n",
    "loss_list = []\n",
    "val_loss_list = []\n",
    "for epoch in range(100):\n",
    "    total_loss = 0\n",
    "    pre_list = []\n",
    "    label_list = []\n",
    "    model.train() \n",
    "\n",
    "    if epoch % 20 == 9:\n",
    "        scheduler1.step()\n",
    "    \n",
    "    for batch_idx, train_data in enumerate(train_dataloader):\n",
    "        data = train_data['data']\n",
    "        data = torch.squeeze(data).unsqueeze(1)\n",
    "        target = train_data['label']\n",
    "        target = torch.tensor(target, dtype=torch.float32)\n",
    "        # print(target)\n",
    "        loss,pre = train_step(data, target)\n",
    "        pre_list.append(pre.item())\n",
    "        label_list.append(target.item())\n",
    "        total_loss = total_loss + loss\n",
    "    # print(total_loss/len(train_dataloader))\n",
    "    loss_list.append(total_loss/len(train_dataloader))\n",
    "    # print(pre_list)\n",
    "    # print(label_list)\n",
    "\n",
    "    model.eval()  # 切换到评估模式\n",
    "        \n",
    "    with torch.no_grad():  # 禁用梯度计算，因为在验证阶段我们不需要反向传播\n",
    "        val_loss_total = 0\n",
    "        val_pre_list = []\n",
    "        val_label_list = []\n",
    "        \n",
    "        for batch_idy, val_dataset in enumerate(val_dataloader):\n",
    "            val_data = val_dataset['data']\n",
    "            val_data = torch.squeeze(val_data).unsqueeze(1)\n",
    "            val_target = val_dataset['label']\n",
    "            val_target = torch.tensor(val_target, dtype=torch.float32)\n",
    "            data, target = val_data.to(device), val_target.to(device)\n",
    "\n",
    "            prediction = model(data)\n",
    "            # print(prediction)\n",
    "            val_loss = val_criterion(prediction, target)\n",
    "            val_loss = val_loss.item()\n",
    "            \n",
    "\n",
    "\n",
    "            val_pre_list.append(prediction.item())\n",
    "            val_label_list.append(val_target.item())\n",
    "            val_loss_total = val_loss_total + val_loss\n",
    "        \n",
    "        # 计算平均验证损失\n",
    "        avg_val_loss = val_loss_total / len(val_dataloader)\n",
    "        val_loss_list.append(val_loss_total / len(val_dataloader))\n",
    "        print(avg_val_loss)\n",
    "        correlation_coefficient = np.corrcoef(val_pre_list, val_label_list)[0, 1]\n",
    "        print(f'Correlation Coefficient: {correlation_coefficient}')\n",
    "        # print(val_pre_list)\n",
    "        # print(val_label_list)\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(loss_list)\n",
    "# val_loss_list2 = []\n",
    "# for i in val_loss_list:\n",
    "#     val_loss_list2.append(i.item())\n",
    "\n",
    "plt.plot(val_loss_list)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
