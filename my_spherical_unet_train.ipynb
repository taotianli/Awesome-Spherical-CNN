{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6722145 paramerters in total\n",
      "0.11331276505688827\n",
      "0.1105934940179189\n",
      "0.11042880231638749\n",
      "0.10922851771612963\n",
      "0.109218665137887\n",
      "0.10852322144806385\n",
      "0.10754507834712665\n",
      "0.10710382728775342\n",
      "0.10665958893299103\n",
      "0.1064228210200866\n",
      "0.10690698397656281\n",
      "0.10620332846542199\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 140\u001b[0m\n\u001b[0;32m    138\u001b[0m     target \u001b[38;5;241m=\u001b[39m target\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;66;03m# print(data.shape)\u001b[39;00m\n\u001b[1;32m--> 140\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    141\u001b[0m     total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28mprint\u001b[39m(total_loss\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(train_dataloader))\n",
      "Cell \u001b[1;32mIn[21], line 92\u001b[0m, in \u001b[0;36mtrain_step\u001b[1;34m(data, target)\u001b[0m\n\u001b[0;32m     89\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     90\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m---> 92\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from layers import Unet_40k\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import scipy.io as sio \n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import nibabel as nib\n",
    "\n",
    "# from utils import compute_weight\n",
    "import matplotlib.pyplot as plt\n",
    "# from tensorboardX import SummaryWriter\n",
    "# writer = SummaryWriter('log/a')\n",
    "\n",
    "################################################################\n",
    "\"\"\" hyper-parameters \"\"\"\n",
    "cuda = torch.device('cuda:0')\n",
    "batch_size = 1\n",
    "model_name = 'Unet_infant'  # 'Unet_infant', 'Unet_18', 'Unet_2ring', 'Unet_repa', 'fcn', 'SegNet', 'SegNet_max'\n",
    "up_layer = 'upsample_interpolation' # 'upsample_interpolation', 'upsample_fixindex' \n",
    "in_channels = 3\n",
    "out_channels = 36\n",
    "learning_rate = 0.001\n",
    "momentum = 0.99\n",
    "weight_decay = 0.0001\n",
    "fold = 1 # 1,2,3 \n",
    "################################################################\n",
    "\n",
    "\n",
    "class BrainSphere(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, root):\n",
    "\n",
    "        self.files = sorted(glob.glob(os.path.join(root, '*\\surf')))\n",
    "        # print(self.files)\n",
    "\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        file = self.files[index]\n",
    "        # print(file)\n",
    "        # print(os.path.join(file, 'lh.ico7.curv'))\n",
    "        curv = nib.freesurfer.io.read_morph_data(os.path.join(file, 'lh.ico6.curv'))\n",
    "        thickness = nib.freesurfer.io.read_morph_data(os.path.join(file, 'lh.ico6.thickness'))\n",
    "        sulc = nib.freesurfer.io.read_morph_data(os.path.join(file, 'lh.ico6.sulc'))\n",
    "        area = nib.freesurfer.io.read_morph_data(os.path.join(file, 'lh.ico6.area'))\n",
    "        curv = torch.from_numpy(curv/np.max(curv)).unsqueeze(1)\n",
    "        thickness = torch.from_numpy(thickness/np.max(thickness)).unsqueeze(1)\n",
    "        sulc = torch.from_numpy(sulc/np.max(sulc)).unsqueeze(1)\n",
    "        area = torch.from_numpy(area/np.max(area)).unsqueeze(1)\n",
    "        # print(curv.shape, thickness.shape, sulc.shape, area.shape)\n",
    "        feats = torch.cat((curv, sulc,thickness), 1)\n",
    "        label = area\n",
    "        return feats, label\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "\n",
    "\n",
    "train_dataset = BrainSphere('F:/New_SphericalNN/')\n",
    "\n",
    "    \n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "# val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True)\n",
    "\n",
    "\n",
    "model = Unet_40k(3, 1, abspath='C:/Users/DELL/Desktop/kaiti/SphericalUNetPackage/sphericalunet/utils')\n",
    "print(\"{} paramerters in total\".format(sum(x.numel() for x in model.parameters())))\n",
    "model.cuda(cuda)\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', factor=0.2, patience=1, verbose=True, threshold=0.0001, threshold_mode='rel', min_lr=0.000001)\n",
    "\n",
    "\n",
    "def train_step(data, target):\n",
    "    model.train()\n",
    "    data, target = data.cuda(cuda), target.cuda(cuda)\n",
    "\n",
    "    prediction = model(data)\n",
    "    # print(prediction)\n",
    "    \n",
    "    loss = criterion(prediction, target)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item()\n",
    "\n",
    "\n",
    "# def compute_dice(pred, gt):\n",
    "\n",
    "#     pred = pred.cpu().numpy()\n",
    "#     gt = gt.cpu().numpy()\n",
    "    \n",
    "#     dice = np.zeros(36)\n",
    "#     for i in range(36):\n",
    "#         gt_indices = np.where(gt == i)[0]\n",
    "#         pred_indices = np.where(pred == i)[0]\n",
    "#         dice[i] = 2 * len(np.intersect1d(gt_indices, pred_indices))/(len(gt_indices) + len(pred_indices))\n",
    "#     return dice\n",
    "\n",
    "\n",
    "# def val_during_training(dataloader):\n",
    "#     model.eval()\n",
    "\n",
    "#     dice_all = np.zeros((len(dataloader),36))\n",
    "#     for batch_idx, (data, target) in enumerate(dataloader):\n",
    "#         data = data.squeeze()\n",
    "#         target = target.squeeze()\n",
    "#         data, target = data.cuda(cuda), target.cuda(cuda)\n",
    "#         with torch.no_grad():\n",
    "#             prediction = model(data)\n",
    "            \n",
    "#         prediction = prediction.max(1)[1]\n",
    "#         dice_all[batch_idx,:] = compute_dice(prediction, target)\n",
    "\n",
    "#     return dice_all\n",
    "\n",
    "from sphericalunet.utils.vtk import read_vtk, write_vtk, resample_label\n",
    "in_file = 'C:/Users/DELL/Desktop/kaiti/Spherical_U-Net/examples/left_hemisphere/40962/test1.lh.40k.vtk'\n",
    "data = read_vtk(in_file)\n",
    "curv_temp = data['curv']\n",
    "n_vertices = 40962\n",
    "curv = torch.from_numpy(data['curv'][0:n_vertices]).unsqueeze(1) # use curv data with 40k vertices\n",
    "sulc = torch.from_numpy(data['sulc'][0:n_vertices]).unsqueeze(1) # use sulc data with 40k vertices\n",
    "\n",
    "\n",
    "train_dice = [0, 0, 0, 0, 0]\n",
    "for epoch in range(100):\n",
    "    total_loss = 0\n",
    "    for batch_idx, (data, target) in enumerate(train_dataloader):\n",
    "        data = data.squeeze()\n",
    "        target = target.squeeze()\n",
    "        # print(data.shape)\n",
    "        loss = train_step(data, target)\n",
    "        total_loss += loss\n",
    "    print(total_loss/len(train_dataloader))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
